---
title: "Classify"
subtitle: "Classification of RNA-Seq samples using circRNA expression"
author: "Carmen Gomez Valenzuela"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Modify base/contrast with the groups in phenodata.txt

phenodata.txt file must contain two columns separated by tabs
 - the first one with the name of samples
 - the second with the group to which each samplebelongs
 
 circ_annotations.rds must contain circRNA read counts with sample names in columns with the same name used in phenodata.txt, and circRNA id in rows.

```{r, message=FALSE}
library(readr)

contrast = "coronary"
base = "normal"

phenodata <- read_delim("phenodata.txt", "\t", escape_double = FALSE, trim_ws = TRUE)
table <- readRDS("circ_anotations.rds")

```

Filtering low expressed circRNAs (less than 10 in 70% of samples or more)

```{r}

counts <- table[,phenodata$File[phenodata$Group %in% c(base,contrast)]]
counts <- counts[ rowSums(counts >= 10) >= dim(counts)[2]*0.7,]
group <- phenodata$Group[phenodata$Group %in% c(base,contrast)]

```

Variance Stabilizing Transformation

```{r}
library(DESeq2)
vst <- vst(as.matrix(counts), fitType="parametric")
```

Split train/test

```{r}

getPartition <- function(group, table, ratio) {
# Esta función devuelve una lista con dos matrices: xtrain y xtest 
# con los datos de entrenamiento y pruebas
# y dos data.frames ytrain e ytest, con las clases de esos dos conjuntos
  
# Argumentos:
#   group = clases de la tabla que recibe por parámetro
#   table = matrix de datos
#   ratio = porcentaje de muestras para pruebas
  
  ind <- c()
  
  for (i in levels(as.factor(group))) {
    gind <- which(group == i)
    nTest = ceiling(length(gind)*ratio)
    
    ind <- c(ind,sample(gind,nTest,FALSE))
  }
  
  data.train = as.matrix(table[,-ind])
  classtr = data.frame(condition = as.factor(group[-ind]))
  
  data.test = as.matrix(table[,ind])
  classts = data.frame(condition = as.factor(group[ind]))
  
  ret <- list("xtrain" = data.train, "xtest" = data.test, 
              "ytrain" = classtr, "ytest" = classts)
  return(ret)
}

set.seed(12345)

dat <- getPartition(as.factor(group), vst,0.2)

xtrain <- dat$xtrain
ytrain <- factor(dat$ytrain$condition)

xtest <- dat$xtest
ytest <- factor(dat$ytest$condition)

```

Predictor selection

```{r}
library(randomForest)

set.seed(12345)

forest.imp = randomForest(class ~. , data = data.frame(t(xtrain), class = ytrain), 
		ntree = 1000, keep.forest = FALSE, importance = TRUE)
		
att.scores = as.data.frame(importance(forest.imp, type = 1))

varImpPlot(forest.imp, cex=0.6)
```

Set K as the desired value (tip: the lower number that makes data grouping in MDS)

```{r}

k=50
selected.circs <- rownames(att.scores)[order(att.scores, decreasing = TRUE)][1:k]
selected.circs

xtrain.cut = xtrain[selected.circs,]

d <- dist(t(xtrain.cut))
mds <- cmdscale(d, k=2) 
plot(mds[,1], mds[,2], type="p", main = paste(contrast, "vs", base, ": Eucledian MDS.",k,"circRNAs"), 
     col = as.numeric(as.factor(ytrain)),pch=as.numeric(as.factor(ytrain)))
legend("topleft", legend=c(contrast, base),
       col= c("black","red"), pch=c(1,2), cex=0.8)
```

#Support Vector Machine model. 

You must tune hyperparams cost and kernel, and set a suitable value for cross-validation folds.

```{r}
set.seed(12345)
library(e1071)

hyper_cost = 2^(0:9)
hyper_kernel = "linear"
cross_folds = 5

svm_tune <- tune.svm(class ~ ., data=data.frame(class=ytrain, t(xtrain.cut)),  
                          cost = hyper_cost, tunecontrol=tune.control(cross=cross_folds))
svm_tune
plot(svm_tune)
```

Predict and evaluate

```{r}
library(caret)
pred.svm <- predict(svm_tune$best.model,t(xtest))
confusionMatrix(pred.svm, ytest)
```

Accuracy report

```{r}
library(pROC)

roc_obj.svm <- roc(as.numeric(as.factor(ytest)), as.numeric(as.factor(pred.svm)))
auc(roc_obj.svm)
plot(roc_obj.svm)
```

#Random Forest Model. 

Set a suitable value for cross-validation folds. 

```{r, fig.height=4}
set.seed(12345)
library(caret)

cross_folds = 5

numFolds <- trainControl(method = 'cv', number = cross_folds, search="random")
tunegrid <- expand.grid(.mtry=seq(1,nrow(xtrain.cut),1))

model_rf <- train(x = t(xtrain.cut), y = as.factor(ytrain), method = "rf",
                trControl = numFolds, tuneGrid=tunegrid, metric="ROC", importance = T, ntree=1000)

model_rf
```

Predict and evaluate

```{r}
library(caret)
pred.rf <- predict(model_rf, t(xtest))
confusionMatrix(pred.rf, ytest)
```

Accuracy report

```{r}
library(pROC)

roc_obj.rf <- roc(as.numeric(as.factor(ytest)), as.numeric(as.factor(pred.rf)))
auc(roc_obj.rf)
plot(roc_obj.rf)
```

#Neural Network Model: Extreme Learning Machine. 

Set a suitable value for cross-falidation folds. 
Tune hyperparams nhid (number of hidden nodes) and acfun (activation function)

```{r}
library(caret)
set.seed(12345)

cross-folds = 5
hyper_nhid = c(1000,1500,2000,2500)
hyper_actfun = c("purelin","sig","sin","radbas","hardlim","hardlims","satlins","tansig","tribas","poslin","purelin")

elm_fun <- getModelInfo("elm")[[1]]

elm_fun$prob <- function (modelFit, newdata, submodels = NULL)  {
  out <- exp(predict(modelFit, newdata))
  t(apply(out, 1, function(x) x/sum(x)))
}

numFolds <- trainControl(method = 'cv', number = cross-folds, search="grid", classProbs = TRUE,
                                      summaryFunction = twoClassSummary)

tunegrid <- expand.grid(nhid= hyper_nhid, actfun= hyper_actfun)

model.nn <- train(x = t(xtrain), y = as.factor(ytrain), method = elm_fun,
                trControl = numFolds, tuneGrid=tunegrid, metric="ROC")

plot(model.nn)
model.nn

```

Predict and evaluate

```{r}
pred.nn <- predict(model.nn,t(xtest))
confusionMatrix(pred.nn, ytest)
```

Accuracy report

```{r}
library(pROC)

roc_obj.nn <- roc(as.numeric(as.factor(ytest)), as.numeric(as.factor(pred.nn)))
auc(roc_obj.nn)
plot(roc_obj.nn)
```